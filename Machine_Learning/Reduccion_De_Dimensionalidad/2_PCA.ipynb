{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio vamos a usar el dataset [MNIST dataset](http://yann.lecun.com/exdb/mnist/). Es un dataset clásico que consiste en 60000 imagenes de números escritos a mano, y el objetivo es clasificar los números.\n",
    "\n",
    "Scikit-learn tiene una función [load_digits](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) que se puede utilizar para cargar el dataset. Sin embargo, dicha función sólo tiene 1700 observaciones. Asi que lo que vamos a hacer es cargar la version completa del dataset que está almacenada en la carpeta data.\n",
    "\n",
    "Para ello usaremos el paquete [pickle](https://docs.python.org/3/library/pickle.html) que es una forma de guardar objetos de python al disco duro y luego poder leerlos de nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./data/mnist.pkl\", \"rb\") as fname:\n",
    "    mnist = pickle.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = mnist[\"training_images\"]\n",
    "mnist_target = mnist[\"training_labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acelerar el ejercicio, vamos a tomar una muestra de 10000 observaciones. **Si en vuestro ordenador tarda mucho, siempre podeis reducir el tamaño mas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56422, 15795,   860, ...,  9484,  5495, 28481])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample_size = 10000\n",
    "np.random.seed(42)\n",
    "random_sample_index = np.random.randint(0, mnist_data.shape[0], sample_size)\n",
    "random_sample_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_muestra_pixeles = mnist_data[random_sample_index]\n",
    "mnist_muestra_clase = mnist_target[random_sample_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usa PCA para reducir la dimensionalidad del dataset (`mnist_muestra_pixeles`) y usa el nuevo dataset como datos de entrenamiento para un clasificador que clasifique correctamente las imagenes. El criterio de evaluacion tiene que ser el criterio F1. Hay varias formas de usar el criterio F1 para casos de multiclase (en este caso hay 10 clases, del número 0 al 9). leer la [documentación del criterio F1 puede ayudar.](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero tenemos que evaluar como es la distribucion de las clases objetivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.1158\n",
       "7    0.1036\n",
       "2    0.1022\n",
       "6    0.1017\n",
       "8    0.1009\n",
       "9    0.0989\n",
       "4    0.0977\n",
       "3    0.0961\n",
       "0    0.0953\n",
       "5    0.0878\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mnist_muestra_clase).value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que no hay imbalance de clases, asi que podemos usar el criterio **micro** de F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos reducir la dimensionalidad pero mantener un 80% de la varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_pca = pca.fit_transform(mnist_muestra_pixeles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 43)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos el estimador, vamos a usar el clasificador KNN, aunque un clasificador de Regresión logística no sería mala idea, dado que la dimensionalidad no es muy alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "busqueda_dist_parametros = {\n",
    "    \"n_neighbors\": sp_randint(2,10),\n",
    "    \"p\": sp_randint(1,3),\n",
    "    \"weights\": [\"uniform\", \"distance\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realizamos la búsqueda aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'n_neighbors': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001DF1F912130>,\n",
       "                                        'p': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001DF1F99AE80>,\n",
       "                                        'weights': ['uniform', 'distance']},\n",
       "                   scoring='f1_micro')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "busqueda = RandomizedSearchCV(estimator=clf,\n",
    "                             param_distributions=busqueda_dist_parametros,\n",
    "                             n_iter=10,\n",
    "                             cv=3,\n",
    "                             n_jobs=-1,\n",
    "                             scoring=\"f1_micro\")\n",
    "busqueda.fit(X=mnist_pca, y=mnist_muestra_clase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9589995592240688"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "busqueda.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 6, 'p': 2, 'weights': 'distance'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "busqueda.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos los mejores parámetros para el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7, weights='distance')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejores_params = {'n_neighbors': 7, 'p': 2, 'weights': 'distance'}\n",
    "clusterer = KNeighborsClassifier(**mejores_params)\n",
    "\n",
    "clusterer.fit(mnist_pca, mnist_muestra_clase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
