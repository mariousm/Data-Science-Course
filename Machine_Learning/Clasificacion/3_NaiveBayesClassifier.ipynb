{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Los clasificadores Naive Bayes (Naive Bayes Classifier - NBC) se usan , como su nombre indica, para problemas de clasificación, y en concreto se pueden aplicar para texto.\n",
    "\n",
    "En este ejemplo vamos a implementar un modelo NBC a un dataset de un portal de Noticias muy famoso en España. Cada usuario comparte un link a una noticia y le puede asignar una categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descripcion</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aunque parezca mentira, las emisiones de dióxi...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hubo un proyecto impulsado por la Unión Europe...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China ha confirmado la conclusión con éxito de...</td>\n",
       "      <td>tecnología</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>En su fructífera carrera como humorista, actor...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tras dos años de negociación entre la instituc...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         descripcion   categoria\n",
       "0  Aunque parezca mentira, las emisiones de dióxi...     cultura\n",
       "1  Hubo un proyecto impulsado por la Unión Europe...     cultura\n",
       "2  China ha confirmado la conclusión con éxito de...  tecnología\n",
       "3  En su fructífera carrera como humorista, actor...     cultura\n",
       "4  Tras dos años de negociación entre la instituc...     cultura"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias = pd.read_csv(\"./data/noticias.csv\")\n",
    "noticias.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable objetivo es categoria y la variable independiente es descripcion que contiene la descripcion de la noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cultura       9001\n",
       "tecnología    4198\n",
       "ocio          3296\n",
       "Name: categoria, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias.categoria.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vemos que hay noticias de 3 tipos de categorías distintas.\n",
    "\n",
    "Los clasificadores Naive Bayes esperan como input un vector, así que para poder entrenarlos tenemos que vectorizar el texto. Para ello una buena opción es usar vectorización Tf-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Eliminar Stopwords\n",
    "\n",
    "Stopwords (palabras vacías) son palabras que no tienen ningún contenido semántico. Por ejemplo, en la frase el perro ladra el artículo el no aporta ningún valor a la frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/stopwords-es.json\") as fname:\n",
    "    stopwords_es = json.load(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar acentos\n",
    "\n",
    "También vamos a eliminar los acentos de las palabras, ésto tiene una ventaja, y es que si en el conjunto de datos no tenemos confianza en la calidad de los escritores, al eliminar los acentos evitamos que si un escritor no usa acentos no considere sus palabras como palabras distintas.\n",
    "\n",
    "En castellano, esto tiene un problema, y es que hay palabras con significado distinto que sólo se diferencian por la existencia de una tilde (se llaman palabras con acento diacrítico (por ejemplo, de y dé). Asumimos pues que el impacto de estas palabras no es muy alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizador = TfidfVectorizer(strip_accents=\"unicode\", stop_words=stopwords_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16495, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<16495x59952 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 397698 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador.fit_transform(noticias.descripcion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicha matriz nos indica que tenemos 16495 artículos que tienen 59969 palabras distintas (sin contar acentos o stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dado que los vectorizadores devuelven una matriz sparse (escasa) creamos un transformador que las convierta a densas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "\n",
    "# http://rasbt.github.io/mlxtend/\n",
    "class DenseTransformer(BaseEstimator):\n",
    "    def __init__(self, return_copy=True):\n",
    "        self.return_copy = return_copy\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        elif self.return_copy:\n",
    "            return X.copy()\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn tiene tres implementaciones del clasificador Naive Bayes, GaussianNB, BernoulliNB y MultinomialNB, y cada una se diferencia por como calcula las probabilidades de que cada elemento aparezca en los datos.\n",
    "\n",
    "GaussianNB asume que los datos siguen una distribución Gausiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_gaussiano = make_pipeline(\n",
    "    vectorizador,\n",
    "    DenseTransformer(),\n",
    "    GaussianNB()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(stop_words=['0', '1', '2', '3', '4', '5', '6',\n",
       "                                             '7', '8', '9', '_', 'a',\n",
       "                                             'actualmente', 'acuerdo',\n",
       "                                             'adelante', 'ademas', 'ademÃ¡s',\n",
       "                                             'adrede', 'afirmÃ³', 'agregÃ³',\n",
       "                                             'ahi', 'ahora', 'ahÃ\\xad', 'al',\n",
       "                                             'algo', 'alguna', 'algunas',\n",
       "                                             'alguno', 'algunos', 'algÃºn', ...],\n",
       "                                 strip_accents='unicode')),\n",
       "                ('densetransformer', DenseTransformer()),\n",
       "                ('gaussiannb', GaussianNB())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_gaussiano.fit(X=noticias.descripcion, y=noticias.categoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cultura', 'cultura', 'tecnología', ..., 'cultura', 'tecnología',\n",
       "       'ocio'], dtype='<U10')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_gaussiano.predict(noticias.descripcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def f1_multietiqueta(estimador, X, y):\n",
    "    preds = estimador.predict(X)\n",
    "    return f1_score(y, preds, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.62988784, 0.64352834, 0.64807517, 0.63776902, 0.63504092])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipeline_gaussiano, noticias.descripcion, noticias.categoria, scoring=f1_multietiqueta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el modelo funciona de igual forma ahora pese a que los datos de entrenamiento son bastante más pequeños (una matriz de dimensión 16495x500 en vez de una de dimensión 16495x59969\n",
    "\n",
    "Las dos implementaciones de clasificadores NB más utilizadas para clasificación de texto son MultinomialNB (que asume que la distribución de probabilidades de las palabras en el conjunto de datos sigue una distribución multinomial y BernouilliNB , que asume que siguen una distribución de Bernouilli multivariable (donde la existencia de cada palabra se considera que es una variable binaria distinta).\n",
    "\n",
    "Según la documentación, el clasificador MultinomialNB funciona bien con vectores TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_multinomial = make_pipeline(\n",
    "    TfidfVectorizer(strip_accents=\"unicode\", stop_words=stopwords_es, max_features=500),\n",
    "    DenseTransformer(),\n",
    "    MultinomialNB(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.68717793, 0.67596241, 0.67202182, 0.68384359, 0.66656563])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipeline_multinomial, noticias.descripcion, noticias.categoria,\n",
    "                scoring=f1_multietiqueta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que efectivamente, MultinomialNB parece funcionar mejor que GaussianNB para vectores TF-IDF.\n",
    "\n",
    "Para el clasificador BernouilliNB se necesita tener los vectores de palabras cono vectores binarios (1 si la palabra existe o 0 si no), así que en vez de usar TfidfVectorizer en este caso usaremos el CountVectorizer pasandole el parámetro binary=True para que devuelva 1 ó 0 en vez del número de veces que aparece la palabra en la frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizador_count = CountVectorizer(stop_words=stopwords_es, binary=True, \n",
    "                                     strip_accents=\"unicode\", max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tierra': 929,\n",
       " 'verde': 969,\n",
       " '30': 25,\n",
       " 'anos': 76,\n",
       " 'epoca': 339,\n",
       " 'principal': 767,\n",
       " 'estudio': 369,\n",
       " 'internacional': 502,\n",
       " 'publicado': 796,\n",
       " 'pasar': 709,\n",
       " 'proyecto': 789,\n",
       " 'union': 950,\n",
       " 'europea': 373,\n",
       " 'metodo': 600,\n",
       " 'lengua': 529,\n",
       " 'espanol': 351,\n",
       " 'sistema': 882,\n",
       " 'espanoles': 353,\n",
       " 'puedan': 802,\n",
       " 'entender': 334,\n",
       " 'china': 167,\n",
       " 'confirmado': 206,\n",
       " 'exito': 381,\n",
       " 'forma': 405,\n",
       " 'totalmente': 935,\n",
       " 'robot': 845,\n",
       " 'logro': 554,\n",
       " 'personal': 726,\n",
       " 'humano': 464,\n",
       " 'carrera': 157,\n",
       " 'actor': 48,\n",
       " 'director': 289,\n",
       " 'escritor': 346,\n",
       " 'decenas': 257,\n",
       " 'peliculas': 712,\n",
       " 'importantes': 478,\n",
       " 'historia': 455,\n",
       " 'cine': 176,\n",
       " 'humor': 466,\n",
       " 'mayoria': 586,\n",
       " 'encuentran': 328,\n",
       " 'publico': 799,\n",
       " 'online': 678,\n",
       " 'mejores': 592,\n",
       " 'museo': 631,\n",
       " 'finalmente': 400,\n",
       " 'siglo': 874,\n",
       " 'musica': 632,\n",
       " 'texto': 926,\n",
       " 'creado': 235,\n",
       " 'nombre': 652,\n",
       " 'obra': 664,\n",
       " 'video': 976,\n",
       " 'hombre': 458,\n",
       " 'comida': 192,\n",
       " 'muestra': 625,\n",
       " 'problema': 773,\n",
       " 'usando': 953,\n",
       " 'google': 434,\n",
       " 'dando': 250,\n",
       " 'mundo': 630,\n",
       " 'lugares': 557,\n",
       " 'alguien': 61,\n",
       " 'ordenador': 684,\n",
       " 'punto': 807,\n",
       " 'rusia': 848,\n",
       " 'norte': 655,\n",
       " 'curioso': 247,\n",
       " 'territorio': 924,\n",
       " 'america': 69,\n",
       " 'gracias': 435,\n",
       " 'empresas': 323,\n",
       " 'asociacion': 99,\n",
       " 'anuncio': 83,\n",
       " 'semana': 863,\n",
       " 'francia': 414,\n",
       " 'vida': 974,\n",
       " 'maquinas': 572,\n",
       " 'arqueologos': 92,\n",
       " 'descubierto': 273,\n",
       " 'prueba': 791,\n",
       " 'piedra': 731,\n",
       " 'media': 587,\n",
       " 'kilometros': 523,\n",
       " 'construir': 218,\n",
       " 'ano': 75,\n",
       " '600': 33,\n",
       " 'metros': 601,\n",
       " 'altura': 67,\n",
       " 'grande': 437,\n",
       " 'edad': 307,\n",
       " 'estructura': 366,\n",
       " 'artificial': 95,\n",
       " 'descubrimiento': 274,\n",
       " 'antiguo': 79,\n",
       " 'obras': 665,\n",
       " 'luz': 560,\n",
       " 'llevado': 549,\n",
       " 'cabo': 130,\n",
       " 'politicos': 745,\n",
       " 'dinero': 285,\n",
       " 'pequeno': 718,\n",
       " 'ocurre': 672,\n",
       " 'demuestra': 267,\n",
       " 'riesgo': 843,\n",
       " 'enfermedades': 332,\n",
       " 'personas': 727,\n",
       " 'peso': 729,\n",
       " 'normal': 654,\n",
       " 'debate': 253,\n",
       " 'torno': 934,\n",
       " 'idea': 468,\n",
       " 'decada': 255,\n",
       " 'importante': 477,\n",
       " 'vista': 983,\n",
       " 'salud': 851,\n",
       " 'publica': 793,\n",
       " 'unica': 946,\n",
       " 'ingles': 495,\n",
       " 'frances': 413,\n",
       " 'aleman': 59,\n",
       " 'ejemplos': 314,\n",
       " 'inicio': 496,\n",
       " 'espanola': 352,\n",
       " 'dejo': 264,\n",
       " 'contar': 221,\n",
       " 'vidas': 975,\n",
       " 'carga': 155,\n",
       " 'artistas': 97,\n",
       " 'especie': 356,\n",
       " 'evolucion': 378,\n",
       " 'seres': 868,\n",
       " 'humanos': 465,\n",
       " 'fuerza': 420,\n",
       " 'seleccion': 862,\n",
       " 'objetivo': 661,\n",
       " 'grupo': 438,\n",
       " 'web': 992,\n",
       " 'internet': 503,\n",
       " 'ultimos': 945,\n",
       " 'convertido': 226,\n",
       " 'millon': 608,\n",
       " 'euros': 375,\n",
       " 'modelo': 614,\n",
       " 'trafico': 939,\n",
       " 'razon': 815,\n",
       " 'ambiente': 68,\n",
       " 'ciencia': 170,\n",
       " 'medicos': 588,\n",
       " 'capaz': 151,\n",
       " 'calle': 134,\n",
       " 'familia': 391,\n",
       " 'resultados': 840,\n",
       " 'nino': 647,\n",
       " 'nivel': 649,\n",
       " '70': 34,\n",
       " 'nasa': 635,\n",
       " 'ordenadores': 685,\n",
       " 'ayuda': 112,\n",
       " 'origen': 687,\n",
       " 'investigador': 505,\n",
       " 'trabajando': 937,\n",
       " 'ideas': 469,\n",
       " 'teoria': 921,\n",
       " 'universidad': 951,\n",
       " 'relacionada': 831,\n",
       " 'contrario': 224,\n",
       " 'especies': 357,\n",
       " 'medida': 589,\n",
       " 'afecta': 52,\n",
       " 'cultura': 245,\n",
       " 'importancia': 476,\n",
       " 'figura': 398,\n",
       " 'republica': 832,\n",
       " 'fotos': 412,\n",
       " '2017': 19,\n",
       " 'ocurrio': 673,\n",
       " 'febrero': 394,\n",
       " 'tipo': 930,\n",
       " 'rio': 844,\n",
       " 'campana': 143,\n",
       " 'cuerpo': 243,\n",
       " 'diario': 279,\n",
       " 'iba': 467,\n",
       " 'viaje': 973,\n",
       " 'muerte': 623,\n",
       " 'par': 700,\n",
       " 'mapas': 570,\n",
       " 'zona': 998,\n",
       " 'espana': 350,\n",
       " 'armas': 91,\n",
       " 'acabar': 40,\n",
       " 'series': 871,\n",
       " 'orden': 683,\n",
       " 'calidad': 132,\n",
       " 'frente': 416,\n",
       " 'pantalla': 698,\n",
       " 'lineas': 537,\n",
       " 'codigo': 186,\n",
       " 'probable': 771,\n",
       " 'justo': 522,\n",
       " 'necesario': 641,\n",
       " 'fuente': 417,\n",
       " 'papel': 699,\n",
       " 'pueblo': 800,\n",
       " '12': 4,\n",
       " 'julio': 520,\n",
       " '000': 0,\n",
       " 'madrid': 562,\n",
       " 'buscar': 128,\n",
       " 'marzo': 578,\n",
       " '2016': 18,\n",
       " 'millones': 609,\n",
       " 'seguridad': 860,\n",
       " 'realmente': 819,\n",
       " 'meses': 599,\n",
       " 'septiembre': 867,\n",
       " '15': 7,\n",
       " 'publicada': 795,\n",
       " 'version': 971,\n",
       " 'exactamente': 379,\n",
       " 'provincia': 788,\n",
       " 'mujer': 627,\n",
       " 'pese': 728,\n",
       " '100': 2,\n",
       " 'habitantes': 442,\n",
       " 'llega': 544,\n",
       " 'ciudad': 177,\n",
       " 'pueblos': 801,\n",
       " '80': 35,\n",
       " 'servicios': 873,\n",
       " 'ciudades': 179,\n",
       " 'animal': 73,\n",
       " 'practicamente': 754,\n",
       " 'trabajadores': 936,\n",
       " 'empresa': 322,\n",
       " 'negocio': 643,\n",
       " 'mil': 605,\n",
       " 'ultima': 943,\n",
       " 'india': 485,\n",
       " 'presentado': 763,\n",
       " 'gobierno': 432,\n",
       " 'australia': 106,\n",
       " '11': 3,\n",
       " '14': 6,\n",
       " 'linux': 538,\n",
       " 'abierto': 37,\n",
       " 'edicion': 308,\n",
       " 'software': 891,\n",
       " 'libre': 533,\n",
       " 'creador': 236,\n",
       " 'control': 225,\n",
       " 'entrevista': 338,\n",
       " 'the': 927,\n",
       " 'ley': 531,\n",
       " 'consumo': 219,\n",
       " 'sol': 892,\n",
       " 'fuerte': 419,\n",
       " 'contiene': 223,\n",
       " 'cantidad': 148,\n",
       " 'ojos': 677,\n",
       " 'contenido': 222,\n",
       " 'puesto': 806,\n",
       " 'actualidad': 51,\n",
       " 'especialmente': 355,\n",
       " 'casos': 161,\n",
       " 'hijos': 454,\n",
       " 'programas': 784,\n",
       " 'atencion': 103,\n",
       " 'oceano': 670,\n",
       " 'mar': 573,\n",
       " 'costa': 232,\n",
       " 'realidad': 818,\n",
       " 'ocasiones': 669,\n",
       " 'conjunto': 207,\n",
       " 'construccion': 216,\n",
       " 'humana': 462,\n",
       " 'antigua': 77,\n",
       " 'europa': 372,\n",
       " 'situado': 887,\n",
       " 'titulo': 932,\n",
       " 'leer': 528,\n",
       " 'probablemente': 772,\n",
       " 'conocida': 209,\n",
       " 'vive': 985,\n",
       " 'actividad': 47,\n",
       " 'generar': 427,\n",
       " 'efecto': 312,\n",
       " 'cadena': 131,\n",
       " 'consecuencias': 213,\n",
       " 'acerca': 46,\n",
       " 'cambios': 141,\n",
       " 'profesor': 781,\n",
       " 'produce': 777,\n",
       " 'modelos': 615,\n",
       " 'aspecto': 100,\n",
       " 'tenia': 919,\n",
       " 'planeta': 735,\n",
       " 'futuro': 424,\n",
       " 'herramientas': 451,\n",
       " 'cambio': 140,\n",
       " 'social': 888,\n",
       " 'decadas': 256,\n",
       " 'viene': 979,\n",
       " 'duda': 304,\n",
       " 'acabo': 41,\n",
       " 'telescopio': 912,\n",
       " 'espacial': 348,\n",
       " 'equipo': 340,\n",
       " 'astronomos': 101,\n",
       " 'negro': 644,\n",
       " 'maximo': 583,\n",
       " 'temperatura': 916,\n",
       " 'atmosfera': 104,\n",
       " 'investigadores': 506,\n",
       " 'agua': 55,\n",
       " '400': 29,\n",
       " 'completo': 197,\n",
       " 'gas': 425,\n",
       " 'dificil': 283,\n",
       " 'resulta': 838,\n",
       " 'superficie': 903,\n",
       " 'deberia': 254,\n",
       " 'seria': 869,\n",
       " 'puntos': 808,\n",
       " 'distancia': 295,\n",
       " 'centro': 165,\n",
       " 'agosto': 54,\n",
       " 'francisco': 415,\n",
       " 'arte': 93,\n",
       " 'paso': 710,\n",
       " 'siglos': 875,\n",
       " 'propiedad': 785,\n",
       " 'gente': 429,\n",
       " 'utiliza': 956,\n",
       " 'incluyendo': 483,\n",
       " 'moviles': 621,\n",
       " 'traves': 941,\n",
       " 'marca': 574,\n",
       " 'historico': 457,\n",
       " 'problemas': 774,\n",
       " 'enfermedad': 331,\n",
       " 'acceder': 42,\n",
       " 'digital': 284,\n",
       " 'mala': 563,\n",
       " 'libros': 535,\n",
       " 'industria': 486,\n",
       " 'existencia': 380,\n",
       " 'libro': 534,\n",
       " 'venta': 967,\n",
       " 'britanica': 125,\n",
       " 'entorno': 335,\n",
       " 'oficial': 675,\n",
       " 'llego': 548,\n",
       " 'jueves': 519,\n",
       " 'investigacion': 504,\n",
       " 'servicio': 872,\n",
       " 'responsable': 833,\n",
       " 'comunicacion': 200,\n",
       " 'twitter': 942,\n",
       " 'encontrado': 324,\n",
       " 'imagenes': 473,\n",
       " 'termino': 922,\n",
       " 'nacional': 634,\n",
       " 'natural': 636,\n",
       " 'unidos': 949,\n",
       " 'local': 552,\n",
       " 'siquiera': 881,\n",
       " 'supone': 905,\n",
       " '60': 32,\n",
       " 'canada': 146,\n",
       " 'grupos': 439,\n",
       " 'palabras': 697,\n",
       " 'viernes': 980,\n",
       " 'encontrar': 325,\n",
       " 'ayuntamiento': 113,\n",
       " 'clave': 182,\n",
       " 'archivos': 89,\n",
       " 'octubre': 671,\n",
       " 'pruebas': 792,\n",
       " '22': 21,\n",
       " '18': 10,\n",
       " 'tipos': 931,\n",
       " 'datos': 251,\n",
       " 'cientificos': 173,\n",
       " 'vuelta': 990,\n",
       " 'conocimiento': 212,\n",
       " 'produccion': 776,\n",
       " 'electrico': 318,\n",
       " 'york': 996,\n",
       " 'mes': 598,\n",
       " 'coche': 184,\n",
       " 'rapido': 814,\n",
       " 'velocidad': 965,\n",
       " 'cabeza': 129,\n",
       " 'naturaleza': 638,\n",
       " 'joven': 514,\n",
       " 'llamado': 542,\n",
       " 'instituto': 497,\n",
       " 'paris': 703,\n",
       " 'premio': 759,\n",
       " 'of': 674,\n",
       " 'londres': 555,\n",
       " 'fotografias': 410,\n",
       " 'alla': 64,\n",
       " 'carlos': 156,\n",
       " 'lunes': 559,\n",
       " 'popular': 747,\n",
       " 'serie': 870,\n",
       " 'mexico': 602,\n",
       " 'hechos': 449,\n",
       " 'documental': 301,\n",
       " 'numero': 660,\n",
       " 'significa': 876,\n",
       " 'concepto': 203,\n",
       " '500': 31,\n",
       " 'san': 852,\n",
       " 'estudios': 370,\n",
       " 'rey': 842,\n",
       " 'ii': 471,\n",
       " 'logrado': 553,\n",
       " '19': 11,\n",
       " '300': 26,\n",
       " 'cuya': 248,\n",
       " 'caracteristicas': 154,\n",
       " 'comun': 199,\n",
       " 'estilo': 363,\n",
       " 'coleccion': 188,\n",
       " 'videojuegos': 977,\n",
       " 'noche': 651,\n",
       " 'diciembre': 280,\n",
       " 'dejado': 262,\n",
       " 'practica': 753,\n",
       " 'presencia': 761,\n",
       " 'accion': 45,\n",
       " 'actual': 49,\n",
       " 'situacion': 886,\n",
       " 'plan': 734,\n",
       " 'ciudadanos': 178,\n",
       " 'desarrollo': 272,\n",
       " 'opinion': 680,\n",
       " 'comunicado': 201,\n",
       " 'puedes': 803,\n",
       " 'carta': 158,\n",
       " 'jamas': 509,\n",
       " '20': 12,\n",
       " 'profundidad': 782,\n",
       " 'entrada': 336,\n",
       " 'camara': 137,\n",
       " 'verano': 968,\n",
       " 'noticia': 656,\n",
       " 'espacio': 349,\n",
       " 'partido': 707,\n",
       " 'puerta': 804,\n",
       " 'sitios': 885,\n",
       " 'encontro': 327,\n",
       " 'junio': 521,\n",
       " 'cambiar': 139,\n",
       " 'decidio': 259,\n",
       " 'utilizan': 958,\n",
       " 'productos': 780,\n",
       " 'funcionamiento': 423,\n",
       " 'universo': 952,\n",
       " '40': 28,\n",
       " 'hora': 460,\n",
       " '50': 30,\n",
       " 'cuestion': 244,\n",
       " 'hallazgo': 448,\n",
       " 'desarrollar': 271,\n",
       " 'espera': 359,\n",
       " 'herramienta': 450,\n",
       " 'lucha': 556,\n",
       " 'cancer': 147,\n",
       " 'explica': 385,\n",
       " 'inglaterra': 494,\n",
       " 'escrito': 345,\n",
       " 'redes': 826,\n",
       " 'imperio': 475,\n",
       " 'mensaje': 595,\n",
       " 'deja': 261,\n",
       " 'proceso': 775,\n",
       " 'recientemente': 822,\n",
       " 'restos': 837,\n",
       " 'ejercito': 315,\n",
       " 'evitar': 377,\n",
       " 'increible': 484,\n",
       " 'llamada': 541,\n",
       " 'marcha': 575,\n",
       " 'alemania': 60,\n",
       " 'estacion': 360,\n",
       " 'coches': 185,\n",
       " 'electricos': 319,\n",
       " 'trabajos': 938,\n",
       " 'responsables': 834,\n",
       " 'pelicula': 711,\n",
       " 'casa': 159,\n",
       " 'mano': 566,\n",
       " 'materiales': 582,\n",
       " 'arboles': 88,\n",
       " 'hombres': 459,\n",
       " 'enero': 330,\n",
       " 'luna': 558,\n",
       " 'protagonista': 786,\n",
       " 'xx': 995,\n",
       " 'fisica': 401,\n",
       " 'famosa': 392,\n",
       " 'especial': 354,\n",
       " 'principio': 769,\n",
       " 'hablamos': 444,\n",
       " 'anunciado': 82,\n",
       " 'ee': 310,\n",
       " 'conocido': 210,\n",
       " 'utilizado': 957,\n",
       " 'companias': 194,\n",
       " 'red': 825,\n",
       " 'tecnologia': 910,\n",
       " 'llegado': 546,\n",
       " 'dejar': 263,\n",
       " 'comunidad': 202,\n",
       " 'calles': 135,\n",
       " 'miembros': 604,\n",
       " 'publicar': 797,\n",
       " 'proteccion': 787,\n",
       " 'acceso': 43,\n",
       " 'decision': 260,\n",
       " 'parque': 704,\n",
       " 'isla': 507,\n",
       " 'creen': 240,\n",
       " 'visto': 984,\n",
       " 'habian': 441,\n",
       " 'superior': 904,\n",
       " 'resto': 836,\n",
       " 'guerra': 440,\n",
       " 'mundial': 629,\n",
       " 'japon': 510,\n",
       " 'ministerio': 610,\n",
       " 'europeo': 374,\n",
       " 'acaba': 39,\n",
       " 'programa': 783,\n",
       " 'usuarios': 955,\n",
       " 'disponible': 292,\n",
       " 'pagina': 693,\n",
       " 'destino': 277,\n",
       " 'blog': 124,\n",
       " 'cientifico': 172,\n",
       " 'desarrollado': 270,\n",
       " 'generacion': 426,\n",
       " 'permite': 723,\n",
       " 'pequenas': 717,\n",
       " 'real': 817,\n",
       " 'animales': 74,\n",
       " 'imagen': 472,\n",
       " 'manos': 567,\n",
       " 'llama': 540,\n",
       " 'partes': 705,\n",
       " 'caso': 160,\n",
       " 'aire': 57,\n",
       " 'plantas': 736,\n",
       " 'energia': 329,\n",
       " 'solar': 893,\n",
       " 'producir': 778,\n",
       " 'electricidad': 317,\n",
       " 'record': 823,\n",
       " 'capacidad': 150,\n",
       " 'nuclear': 659,\n",
       " 'civil': 180,\n",
       " 'compania': 193,\n",
       " 'aplicacion': 85,\n",
       " '10': 1,\n",
       " 'larga': 527,\n",
       " 'piezas': 733,\n",
       " 'peligro': 713,\n",
       " 'vehiculos': 964,\n",
       " 'crear': 237,\n",
       " 'momentos': 616,\n",
       " 'artista': 96,\n",
       " 'sector': 856,\n",
       " 'actuales': 50,\n",
       " 'paises': 695,\n",
       " 'revista': 841,\n",
       " 'cientifica': 171,\n",
       " 'expertos': 384,\n",
       " 'articulo': 94,\n",
       " 'unico': 947,\n",
       " 'capaces': 149,\n",
       " 'sistemas': 883,\n",
       " 'siguen': 877,\n",
       " 'material': 581,\n",
       " 'contacto': 220,\n",
       " 'sociedad': 890,\n",
       " 'persona': 724,\n",
       " 'algun': 62,\n",
       " 'rojo': 846,\n",
       " 'dios': 286,\n",
       " 'precio': 755,\n",
       " 'memoria': 593,\n",
       " 'sentido': 866,\n",
       " 'satelite': 854,\n",
       " 'pequena': 716,\n",
       " 'suficiente': 902,\n",
       " 'region': 828,\n",
       " 'periodo': 722,\n",
       " 'diseno': 291,\n",
       " 'primeras': 766,\n",
       " 'vineta': 981,\n",
       " 'ficcion': 397,\n",
       " 'experimento': 383,\n",
       " 'diversas': 299,\n",
       " 'parecer': 702,\n",
       " 'xix': 994,\n",
       " 'madre': 561,\n",
       " 'fuentes': 418,\n",
       " 'salir': 850,\n",
       " 'plataforma': 737,\n",
       " 'objetos': 663,\n",
       " 'marte': 576,\n",
       " 'formacion': 406,\n",
       " 'falta': 390,\n",
       " 'descubrir': 276,\n",
       " 'podia': 740,\n",
       " 'original': 688,\n",
       " 'incluye': 482,\n",
       " 'escribir': 344,\n",
       " 'agencia': 53,\n",
       " 'km': 524,\n",
       " 'segundos': 858,\n",
       " 'seguir': 857,\n",
       " 'android': 72,\n",
       " 'gigante': 430,\n",
       " 'cuyo': 249,\n",
       " 'posibilidad': 749,\n",
       " '200': 13,\n",
       " 'economico': 306,\n",
       " 'militar': 607,\n",
       " 'mision': 612,\n",
       " 'campo': 144,\n",
       " 'batalla': 120,\n",
       " 'oro': 689,\n",
       " 'estrella': 364,\n",
       " 'tecnicas': 909,\n",
       " 'fotografia': 409,\n",
       " 'camaras': 138,\n",
       " 'tenian': 920,\n",
       " 'vehiculo': 963,\n",
       " 'antiguedad': 78,\n",
       " 'crecimiento': 238,\n",
       " 'cerebro': 166,\n",
       " 'tamano': 907,\n",
       " 'pequenos': 719,\n",
       " 'obtener': 667,\n",
       " 'television': 913,\n",
       " 'jefe': 511,\n",
       " 'llamar': 543,\n",
       " 'derechos': 269,\n",
       " 'autor': 107,\n",
       " 'informe': 490,\n",
       " 'muestran': 626,\n",
       " 'evidencia': 376,\n",
       " 'linea': 536,\n",
       " 'ningun': 646,\n",
       " 'noticias': 657,\n",
       " 'solucion': 894,\n",
       " 'nacio': 633,\n",
       " 'interior': 501,\n",
       " 'muerto': 624,\n",
       " 'causa': 162,\n",
       " 'ultimas': 944,\n",
       " '23': 22,\n",
       " 'cultural': 246,\n",
       " 'jovenes': 515,\n",
       " 'busca': 127,\n",
       " 'informacion': 488,\n",
       " 'microsoft': 603,\n",
       " 'facebook': 388,\n",
       " 'funciona': 422,\n",
       " 'disenado': 290,\n",
       " 'nave': 639,\n",
       " 'condiciones': 205,\n",
       " 'david': 252,\n",
       " 'famoso': 393,\n",
       " 'reciente': 821,\n",
       " 'respuesta': 835,\n",
       " 'navegador': 640,\n",
       " 'conoce': 208,\n",
       " 'vemos': 966,\n",
       " 'demas': 265,\n",
       " 'aplicaciones': 86,\n",
       " 'perdida': 720,\n",
       " 'hablar': 445,\n",
       " 'suelen': 899,\n",
       " 'distintos': 297,\n",
       " 'uu': 961,\n",
       " 'diferencia': 282,\n",
       " '90': 36,\n",
       " 'vuelve': 991,\n",
       " 'minutos': 611,\n",
       " 'california': 133,\n",
       " 'interesante': 500,\n",
       " 'semanas': 864,\n",
       " 'informatica': 489,\n",
       " 'fenomeno': 396,\n",
       " 'educacion': 309,\n",
       " 'fecha': 395,\n",
       " 'banda': 116,\n",
       " 'personajes': 725,\n",
       " 'calor': 136,\n",
       " 'suelo': 900,\n",
       " 'estadounidense': 361,\n",
       " 'poblacion': 739,\n",
       " 'relacion': 830,\n",
       " 'principios': 770,\n",
       " 'particulas': 706,\n",
       " 'alta': 65,\n",
       " 'temperaturas': 917,\n",
       " 'directamente': 288,\n",
       " 'fotografo': 411,\n",
       " 'ingeniero': 492,\n",
       " 'movimiento': 622,\n",
       " 'finales': 399,\n",
       " 'tecnica': 908,\n",
       " 'cien': 169,\n",
       " '2015': 17,\n",
       " 'humanidad': 463,\n",
       " 'razones': 816,\n",
       " 'aviones': 111,\n",
       " 'cielo': 168,\n",
       " 'motivo': 618,\n",
       " 'capital': 152,\n",
       " 'golpe': 433,\n",
       " 'explicar': 386,\n",
       " 'perdido': 721,\n",
       " 'mayores': 585,\n",
       " 'distribucion': 298,\n",
       " 'efectos': 313,\n",
       " 'decidido': 258,\n",
       " 'recursos': 824,\n",
       " 'juegos': 518,\n",
       " 'miles': 606,\n",
       " 'compartir': 195,\n",
       " 'sociales': 889,\n",
       " 'mercado': 597,\n",
       " 'apple': 87,\n",
       " 'autores': 108,\n",
       " 'publicacion': 794,\n",
       " 'ocasion': 668,\n",
       " 'aguas': 56,\n",
       " 'policia': 743,\n",
       " 'cientos': 174,\n",
       " 'habria': 447,\n",
       " 'impresionante': 480,\n",
       " 'comenzo': 191,\n",
       " 'blanco': 123,\n",
       " 'global': 431,\n",
       " 'volver': 987,\n",
       " 'padre': 690,\n",
       " 'accidente': 44,\n",
       " 'dolares': 303,\n",
       " 'baja': 115,\n",
       " 'pagar': 692,\n",
       " 'direccion': 287,\n",
       " 'telefono': 911,\n",
       " 'suele': 898,\n",
       " 'concreto': 204,\n",
       " 'principales': 768,\n",
       " 'dispositivo': 293,\n",
       " 'corazon': 230,\n",
       " 'operativo': 679,\n",
       " 'windows': 993,\n",
       " 'usuario': 954,\n",
       " 'tendra': 918,\n",
       " 'base': 119,\n",
       " 'manana': 564,\n",
       " 'completamente': 196,\n",
       " 'sonda': 895,\n",
       " 'abril': 38,\n",
       " 'detalles': 278,\n",
       " 'genero': 428,\n",
       " 'ofrece': 676,\n",
       " 'observar': 666,\n",
       " 'habra': 446,\n",
       " 'rajoy': 813,\n",
       " 'radio': 812,\n",
       " 'in': 481,\n",
       " 'duro': 305,\n",
       " 'ninos': 648,\n",
       " 'mostrar': 617,\n",
       " 'piel': 732,\n",
       " '2013': 15,\n",
       " 'aparece': 84,\n",
       " 'polemica': 742,\n",
       " 'llegada': 545,\n",
       " 'impacto': 474,\n",
       " 'voz': 988,\n",
       " 'tiempos': 928,\n",
       " 'alto': 66,\n",
       " 'utilizando': 959,\n",
       " 'publicidad': 798,\n",
       " 'posicion': 750,\n",
       " 'motor': 619,\n",
       " 'necesidad': 642,\n",
       " 'suerte': 901,\n",
       " 'mayo': 584,\n",
       " 'reino': 829,\n",
       " 'unido': 948,\n",
       " 'mapa': 569,\n",
       " 'enorme': 333,\n",
       " 'new': 645,\n",
       " 'pluton': 738,\n",
       " 'area': 90,\n",
       " 'orbita': 682,\n",
       " 'mujeres': 628,\n",
       " 'organizacion': 686,\n",
       " 'masa': 579,\n",
       " 'cree': 239,\n",
       " 'manel': 565,\n",
       " 'fontdevila': 404,\n",
       " 'llevan': 550,\n",
       " 'foto': 408,\n",
       " 'sorprendente': 896,\n",
       " 'funcion': 421,\n",
       " 'vivir': 986,\n",
       " 'post': 751,\n",
       " 'campos': 145,\n",
       " '16': 8,\n",
       " 'cierre': 175,\n",
       " 'sorpresa': 897,\n",
       " 'estadounidenses': 362,\n",
       " 'producto': 779,\n",
       " 'tesla': 925,\n",
       " 'experiencia': 382,\n",
       " 'derecho': 268,\n",
       " 'presente': 764,\n",
       " 'estudiar': 368,\n",
       " 'juego': 517,\n",
       " 'pasa': 708,\n",
       " 'extrano': 387,\n",
       " 'medios': 590,\n",
       " 'cualquiera': 242,\n",
       " 'tema': 914,\n",
       " '2012': 14,\n",
       " 'queda': 810,\n",
       " 'bernardo': 122,\n",
       " 'vergara': 970,\n",
       " 'seguro': 861,\n",
       " 'clase': 181,\n",
       " 'movil': 620,\n",
       " 'precisamente': 756,\n",
       " 'similar': 878,\n",
       " 'utilizar': 960,\n",
       " 'mejorar': 591,\n",
       " 'parecen': 701,\n",
       " 've': 962,\n",
       " 'facil': 389,\n",
       " 'imposible': 479,\n",
       " 'convierte': 228,\n",
       " 'sur': 906,\n",
       " 'central': 164,\n",
       " '3d': 27,\n",
       " 'celulas': 163,\n",
       " 'lista': 539,\n",
       " 'resultado': 839,\n",
       " 'interes': 499,\n",
       " '13': 5,\n",
       " 'amigos': 70,\n",
       " 'empezo': 321,\n",
       " 'antiguos': 80,\n",
       " 'documentos': 302,\n",
       " 'diez': 281,\n",
       " 'camino': 142,\n",
       " 'tomar': 933,\n",
       " 'clientes': 183,\n",
       " 'habitual': 443,\n",
       " 'padres': 691,\n",
       " 'puso': 809,\n",
       " 'azul': 114,\n",
       " 'vuelo': 989,\n",
       " 'jose': 513,\n",
       " 'vision': 982,\n",
       " 'menor': 594,\n",
       " 'zonas': 999,\n",
       " 'fondo': 403,\n",
       " 'convertirse': 227,\n",
       " 'llegar': 547,\n",
       " '25': 24,\n",
       " 'libertad': 532,\n",
       " 'pp': 752,\n",
       " 'diversos': 300,\n",
       " 'john': 512,\n",
       " 'prensa': 760,\n",
       " 'creacion': 234,\n",
       " 'romano': 847,\n",
       " 'peninsula': 714,\n",
       " 'cara': 153,\n",
       " 'industrial': 487,\n",
       " 'baterias': 121,\n",
       " 'barcelona': 117,\n",
       " 'martin': 577,\n",
       " 'dispositivos': 294,\n",
       " 'ataque': 102,\n",
       " 'alimentos': 63,\n",
       " 'proyectos': 790,\n",
       " 'via': 972,\n",
       " 'lenguaje': 530,\n",
       " 'mente': 596,\n",
       " 'descubrio': 275,\n",
       " 'podido': 741,\n",
       " 'ruso': 849,\n",
       " 'conseguido': 214,\n",
       " 'analisis': 71,\n",
       " 'simple': 879,\n",
       " 'escena': 343,\n",
       " 'videos': 978,\n",
       " 'fisico': 402,\n",
       " 'youtube': 997,\n",
       " 'formas': 407,\n",
       " 'ido': 470,\n",
       " 'asegura': 98,\n",
       " 'pone': 746,\n",
       " 'inteligencia': 498,\n",
       " 'colores': 190,\n",
       " 'cosa': 231,\n",
       " 'preguntas': 758,\n",
       " 'materia': 580,\n",
       " '17': 9,\n",
       " 'paginas': 694,\n",
       " 'convirtio': 229,\n",
       " 'eeuu': 311,\n",
       " 'pie': 730,\n",
       " 'cohete': 187,\n",
       " 'escala': 342,\n",
       " 'avion': 110,\n",
       " '21': 20,\n",
       " 'oportunidad': 681,\n",
       " 'coste': 233,\n",
       " 'alcanzar': 58,\n",
       " 'estrellas': 365,\n",
       " 'estudiantes': 367,\n",
       " 'britanico': 126,\n",
       " 'etc': 371,\n",
       " 'sencilla': 865,\n",
       " 'palabra': 696,\n",
       " 'mantener': 568,\n",
       " 'demostrado': 266,\n",
       " 'crisis': 241,\n",
       " 'seguramente': 859,\n",
       " '2014': 16,\n",
       " '24': 23,\n",
       " 'islas': 508,\n",
       " 'nombres': 653,\n",
       " 'naturales': 637,\n",
       " 'juan': 516,\n",
       " 'puerto': 805,\n",
       " 'temas': 915,\n",
       " 'distintas': 296,\n",
       " 'color': 189,\n",
       " 'pregunta': 757,\n",
       " 'historias': 456,\n",
       " 'presidente': 765,\n",
       " 'mitad': 613,\n",
       " 'lanzamiento': 526,\n",
       " 'construido': 217,\n",
       " 'autoridades': 109,\n",
       " 'electrica': 316,\n",
       " 'presenta': 762,\n",
       " 'llevo': 551,\n",
       " 'conocidos': 211,\n",
       " 'politica': 744,\n",
       " 'ingenieros': 493,\n",
       " 'aumento': 105,\n",
       " 'niveles': 650,\n",
       " 'hospital': 461,\n",
       " 'grafico': 436,\n",
       " 'comportamiento': 198,\n",
       " 'noviembre': 658,\n",
       " 'antonio': 81,\n",
       " 'elementos': 320,\n",
       " 'entrar': 337,\n",
       " 'pensar': 715,\n",
       " 'maquina': 571,\n",
       " 'quieren': 811,\n",
       " 'transporte': 940,\n",
       " 'barco': 118,\n",
       " 'terreno': 923,\n",
       " 'error': 341,\n",
       " 'populares': 748,\n",
       " 'laboratorio': 525,\n",
       " 'sitio': 884,\n",
       " 'objeto': 662,\n",
       " 'escuela': 347,\n",
       " 'recibido': 820,\n",
       " 'simplemente': 880,\n",
       " 'hielo': 452,\n",
       " 'espectacular': 358,\n",
       " 'encontraron': 326,\n",
       " 'ingenieria': 491,\n",
       " 'hijo': 453,\n",
       " 'secreto': 855,\n",
       " 'reducir': 827,\n",
       " 'sangre': 853,\n",
       " 'considerado': 215}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador_count.fit(noticias.descripcion)\n",
    "vectorizador_count.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bernouilli = make_pipeline(\n",
    "    vectorizador_count,\n",
    "    DenseTransformer(),\n",
    "    BernoulliNB(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\mario\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aa', 'aaon', 'adema', 'adia3', 'afirma3', 'agrega3', 'aha', 'ais', 'ala3', 'algaon', 'alla', 'amos', 'an', 'antaa', 'aoltima', 'aoltimas', 'aoltimo', 'aoltimos', 'aqua', 'as', 'asa', 'asegura3', 'bamos', 'ca3mo', 'comenta3', 'considera3', 'cua', 'da3nde', 'deja3', 'dema', 'despua', 'detra', 'estara', 'estuvia', 'explica3', 'expresa3', 'fua', 'haba', 'habra', 'hubia', 'indica3', 'informa3', 'is', 'lla', 'llas', 'llega3', 'llos', 'ma', 'manifesta3', 'menciona3', 'ndo', 'nes', 'ningaon', 'nta', 'ntas', 'nto', 'ntos', 'paa', 'podra', 'pra3ximo', 'pra3ximos', 'qua', 'queda3', 'quia', 'ramos', 'realiza3', 'sa', 'sa3lo', 'sas', 'segaon', 'semos', 'sos', 'sta', 'stas', 'ste', 'stos', 'tambia', 'tao', 'tena', 'tendra', 'todava', 'trava', 'tuvia'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.67262807, 0.68293422, 0.69051228, 0.6880873 , 0.67293119])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipeline_bernouilli, noticias.descripcion, noticias.categoria, scoring=f1_multietiqueta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
